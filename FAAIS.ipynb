{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.10.0-cp312-cp312-win_amd64.whl.metadata (4.5 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.0.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (2.1.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from faiss-cpu) (24.1)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (0.29.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.11.0->sentence-transformers) (75.8.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\av709\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Downloading faiss_cpu-1.10.0-cp312-cp312-win_amd64.whl (13.7 MB)\n",
      "   ---------------------------------------- 0.0/13.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/13.7 MB 4.2 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.8/13.7 MB 5.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.7/13.7 MB 8.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.0/13.7 MB 8.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 9.4/13.7 MB 9.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.1/13.7 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.6/13.7 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.7/13.7 MB 9.7 MB/s eta 0:00:00\n",
      "Downloading sentence_transformers-4.0.1-py3-none-any.whl (340 kB)\n",
      "Downloading transformers-4.50.3-py3-none-any.whl (10.2 MB)\n",
      "   ---------------------------------------- 0.0/10.2 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 2.9/10.2 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.6/10.2 MB 16.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.2 MB 15.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.2/10.2 MB 15.5 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   -------------------------------------- - 2.4/2.4 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 11.6 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, regex, faiss-cpu, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed faiss-cpu-1.10.0 regex-2024.11.6 safetensors-0.5.3 sentence-transformers-4.0.1 tokenizers-0.21.1 transformers-4.50.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu sentence-transformers pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as legal_texts.csv!\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"viber1/indian-law-dataset\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(dataset[\"train\"])\n",
    "\n",
    "# Save as CSV\n",
    "df.to_csv(\"legal_texts.csv\", index=False)\n",
    "\n",
    "print(\"Dataset saved as legal_texts.csv!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load legal dataset (Ensure the dataset file exists)\n",
    "df = pd.read_csv(\"legal_texts.csv\")  # This should have the 'response' column\n",
    "\n",
    "# Load embedding model\n",
    "embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Convert all legal texts to embeddings\n",
    "embeddings = embedder.encode(df[\"Response\"].tolist(), convert_to_tensor=True).cpu().numpy()\n",
    "\n",
    "# Create FAISS index\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "# Save FAISS index\n",
    "faiss.write_index(index, \"legal_faiss.index\")\n",
    "\n",
    "print(\"FAISS index saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24601/24601 [04:12<00:00, 97.38it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to instruction_embeddings.npy\n",
      "FAISS index saved to legal_faiss.index\n",
      "Responses saved to legal_responses.csv\n",
      "✅ Embeddings & FAISS index generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load CSV (Update the file path if needed)\n",
    "CSV_PATH = \"legal_texts.csv\"  # Replace with your actual file name\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Ensure column names are correctly named\n",
    "df.rename(columns={\"Instruction\": \"instruction\", \"Response\": \"response\"}, inplace=True)\n",
    "\n",
    "# Drop rows where \"instruction\" is NaN\n",
    "df = df.dropna(subset=[\"instruction\"])\n",
    "\n",
    "# Check if \"instruction\" column exists\n",
    "if \"instruction\" not in df.columns:\n",
    "    raise KeyError(\"The CSV file must contain a column named 'instruction'.\")\n",
    "\n",
    "# Load a pre-trained embedding model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Generate embeddings for the instruction column\n",
    "print(\"Generating embeddings...\")\n",
    "embeddings = np.array([model.encode(str(text)) for text in tqdm(df[\"instruction\"])])\n",
    "\n",
    "# Save embeddings\n",
    "EMBEDDINGS_PATH = \"instruction_embeddings.npy\"\n",
    "np.save(EMBEDDINGS_PATH, embeddings)\n",
    "print(f\"Embeddings saved to {EMBEDDINGS_PATH}\")\n",
    "\n",
    "# Create FAISS index\n",
    "dimension = embeddings.shape[1]  # Get the embedding size\n",
    "faiss_index = faiss.IndexFlatL2(dimension)\n",
    "faiss_index.add(embeddings)\n",
    "\n",
    "# Save FAISS index\n",
    "FAISS_INDEX_PATH = \"legal_faiss.index\"\n",
    "faiss.write_index(faiss_index, FAISS_INDEX_PATH)\n",
    "print(f\"FAISS index saved to {FAISS_INDEX_PATH}\")\n",
    "\n",
    "# Save responses for retrieval\n",
    "df.to_csv(\"legal_responses.csv\", index=False)\n",
    "print(\"Responses saved to legal_responses.csv\")\n",
    "\n",
    "print(\"✅ Embeddings & FAISS index generated successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
